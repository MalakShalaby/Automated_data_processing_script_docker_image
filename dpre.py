# -*- coding: utf-8 -*-
"""dpre

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/180tfhwFAZdSTjoOfPjyGSD3N7n9iQf0X
"""
import subprocess
import sys
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
# Check if the user provided the dataset file path as an argument
if len(sys.argv) != 2:
    print("Usage: python dpre.py <file_path>")
    sys.exit(1)

# Get the file path from the command-line argument
file_path = sys.argv[1]

try:
    # Load the dataset
    df = pd.read_csv(file_path)

    # Data Cleaning
    # 1) Handle missing values
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['Cabin'].fillna(df['Cabin'].mode()[0], inplace=True)
    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

    # 2) Remove duplicates
    df.drop_duplicates(inplace=True)

#______________________________________________________________________________________________________________________

    # Data Reduction
    # 1) Feature selection
    selected_columns = ['Pclass', 'Age','Fare', 'Sex','SibSp', 'Parch','Embarked','Survived']
    df = df[selected_columns]

    # 2) Dimensionality reduction (PCA)
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2)
    df[['PCA1', 'PCA2']] = pca.fit_transform(df[['SibSp', 'Parch']])

#______________________________________________________________________________________________________________________

    # Data Transformation
    # 1) Feature scaling (Min-Max scaling)
    scaler = MinMaxScaler()
    numerical_features = ["Age", "Fare"]
    df[numerical_features] = scaler.fit_transform(df[numerical_features])

#______________________________________________________________________________________________________________________
    # Data Discretization
    # 1) Discretize a continuous variable (e.g., age groups)
    df['Age'] = pd.cut(df['Age'], bins=[0, 18, 40, 60, float('inf')], labels=['0-18', '19-40', '41-60', '61+'])

    # 2) Equal Frequency/Binning
    df["Fare"] = pd.qcut(df["Fare"], q=3, labels=["Low Fare", "Medium Fare", "High Fare"])
    
#______________________________________________________________________________________________________________________
    # Data Transformation
    # 3) One-hot encoding
    df = pd.get_dummies(df, columns=['Age','Fare', 'Sex','Embarked'])

    # Save the resulting data frame to a new CSV file
    df.to_csv('res_dpre.csv', index=False)

#______________________________________________________________________________________________________________________


except FileNotFoundError:
    print(f"File not found: {file_path}")

except Exception as e:
    print(f"An error occurred: {e}")
    

subprocess.run(["python3", "eda.py", "titanic.csv"])

